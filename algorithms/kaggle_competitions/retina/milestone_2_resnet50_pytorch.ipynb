{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>Author : Nadine Mohamed (20162200)\n",
    "</br>Date : 12/12/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "\n",
    "# modify the following\n",
    "path_train_data = \"./data/train_data.pkl\"\n",
    "path_test_data = \"./data/test_data.pkl\"\n",
    "\n",
    "# ResNET50 Hyperparameters\n",
    "dropout_rate = 0.6533917677589358\n",
    "lr = 0.00013562523589705295\n",
    "weight_decay = 1.4871085437648996e-05\n",
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class for loading and transforming retinal images.\n",
    "    \"\"\"\n",
    "    def __init__(self, images, labels=None, transform=None):\n",
    "        self.images = images.astype(np.float32)\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        img = np.stack([img, img, img], axis=-1)\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return img, label\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class finalResNetModel:\n",
    "    \"\"\"\n",
    "    A final model class for training and evaluating a ResNet50 model on the retinal dataset.\n",
    "    Adapts the style of simpleNN but uses PyTorch and a pretrained ResNet50 architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=4, dropout_rate=0.6533917677589358, lr=0.00013562523589705295, \n",
    "                 weight_decay=1.4871085437648996e-05, seed=42, device=None):\n",
    "        \"\"\"\n",
    "        Initializes the ResNet50 model with given hyperparameters.\n",
    "\n",
    "        args:\n",
    "            num_classes : int\n",
    "                Number of output classes.\n",
    "            dropout_rate : float\n",
    "                Dropout rate for the final layer.\n",
    "            lr : float\n",
    "                Learning rate.\n",
    "            weight_decay : float\n",
    "                Weight decay (L2 regularization).\n",
    "            seed : int\n",
    "                Random seed.\n",
    "            device : torch.device\n",
    "                Device to run computations on (e.g. torch.device('cuda')).\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        self.device = device if device is not None else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Load pretrained ResNet50\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        in_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(in_ftrs, num_classes)\n",
    "        )\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        \"\"\"\n",
    "        Trains the model for one epoch on the training data.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(X_batch)\n",
    "            loss = self.criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "\n",
    "        avg_loss = running_loss / total\n",
    "        accuracy = correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        \"\"\"\n",
    "        Evaluates the model on given data_loader.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in data_loader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device)\n",
    "                outputs = self.model(X_batch)\n",
    "                loss = self.criterion(outputs, y_batch)\n",
    "\n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (preds == y_batch).sum().item()\n",
    "\n",
    "        avg_loss = running_loss / total\n",
    "        accuracy = correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def predict(self, data_loader):\n",
    "        \"\"\"\n",
    "        Predicts class labels for the given data_loader.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch in data_loader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                outputs = self.model(X_batch)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "        return np.array(all_preds)\n",
    "\n",
    "    def fit(self, train_loader, val_loader, epochs=10, patience=10):\n",
    "        \"\"\"\n",
    "        Trains the model using training and validation data loaders.\n",
    "\n",
    "        args:\n",
    "            train_loader : DataLoader\n",
    "                DataLoader for training data\n",
    "            val_loader : DataLoader\n",
    "                DataLoader for validation data\n",
    "            epochs : int\n",
    "                Number of epochs.\n",
    "            patience : int\n",
    "                Early stopping patience.\n",
    "        \"\"\"\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self.train_one_epoch(train_loader)\n",
    "            val_loss, val_acc = self.evaluate(val_loader)\n",
    "\n",
    "            if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "                print(\n",
    "                    f\"Epoch {epoch+1}/{epochs} \"\n",
    "                    f\"- Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                    f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "                )\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(self.model.state_dict(), 'final_pretrained_model.pth')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"early stopping\")\n",
    "                break\n",
    "\n",
    "    def load_best(self, path='final_pretrained_model.pth'):\n",
    "        \"\"\"\n",
    "        Loads the best model weights saved during training.\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\ns99a/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:04<00:00, 22.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "with open(path_train_data, \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "train_images = np.array(train_data[\"images\"])\n",
    "train_labels = np.array(train_data[\"labels\"])\n",
    "\n",
    "# split into train/val\n",
    "X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    ")\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = RetinalDataset(X_train_np, y_train_np, transform=train_transform)\n",
    "val_dataset = RetinalDataset(X_val_np, y_val_np, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "model = finalResNetModel()\n",
    "model.fit(train_loader, val_loader, epochs=10, patience=10)\n",
    "model.load_best()\n",
    "\n",
    "# Evaluate on test set or predict on unlabeled data as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to 'submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test (unlabeled) data\n",
    "with open(path_test_data, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "X_test = np.array(test_data['images'])\n",
    "\n",
    "test_dataset = RetinalDataset(X_test, labels=None, transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "test_preds = model.predict(test_loader)\n",
    "\n",
    "with open('submission.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"ID\", \"Class\"])\n",
    "    for i, pred in enumerate(test_preds, start=1):\n",
    "        writer.writerow([i, pred])\n",
    "\n",
    "print(\"Submission saved to 'submission.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources/references:\n",
    "\n",
    "1. IFT6390 Course material \n",
    "2. Torchvision Documentation : https://pytorch.org/vision/main/models.html\n",
    "3. Torchvision Documentation : https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
    "4. The help of AI tools (Co-pilot, ChatGPT, Gemini) \n",
    "AI tools, including GitHub Co-pilot and ChatGPT, were utilized during the coding process. These tools primarily contributed to generating docstrings, refining code structure, and offering suggestions inline within the IDE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
